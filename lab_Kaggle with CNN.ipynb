{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab: Kaggle Competition - Digit Recognizer\n",
    "\n",
    "## Using Convolutional Neural Network (CNN) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Competition Description**\n",
    "\n",
    "MNIST (\"Modified National Institute of Standards and Technology\") is the de facto “hello world” dataset of computer vision. Since its release in 1999, this classic dataset of handwritten images has served as the basis for benchmarking classification algorithms. As new machine learning techniques emerge, MNIST remains a reliable resource for researchers and learners alike.\n",
    "\n",
    "In this competition, your goal is to correctly identify digits from a dataset of tens of thousands of handwritten images. We’ve curated a set of tutorial-style kernels which cover everything from regression to neural networks. We encourage you to experiment with different algorithms to learn first-hand what works well and how techniques compare.\n",
    "\n",
    "**Skills**\n",
    "\n",
    "- Computer vision fundamentals including simple neural networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Input, Dropout, Conv2D, MaxPool2D, Flatten\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load training data\n",
    "\n",
    "Load `train.csv` from Kaggle into a pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
       "0      1       0       0       0       0       0       0       0       0   \n",
       "1      0       0       0       0       0       0       0       0       0   \n",
       "2      1       0       0       0       0       0       0       0       0   \n",
       "3      4       0       0       0       0       0       0       0       0   \n",
       "4      0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel8    ...     pixel774  pixel775  pixel776  pixel777  pixel778  \\\n",
       "0       0    ...            0         0         0         0         0   \n",
       "1       0    ...            0         0         0         0         0   \n",
       "2       0    ...            0         0         0         0         0   \n",
       "3       0    ...            0         0         0         0         0   \n",
       "4       0    ...            0         0         0         0         0   \n",
       "\n",
       "   pixel779  pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0         0  \n",
       "1         0         0         0         0         0  \n",
       "2         0         0         0         0         0  \n",
       "3         0         0         0         0         0  \n",
       "4         0         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42000, 785)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training.shape\n",
    "# 42000 rows (images), 785 columns (representing each pixel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up X and y\n",
    "\n",
    "NOTE: Keras requires a `numpy` matrix, it doesn't work with `pandas`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = training['label'].values   # label column classifying the numbers\n",
    "X = training[training.columns[1:]].values  # all the remaining columns after that, containing pixel data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing\n",
    "\n",
    "1. When dealing with image data, you need to normalize your `X` by dividing each value by the max number of pixels (255).\n",
    "2. Since this is a multiclass classification problem, keras needs `y` to be a one-hot encoded matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Normalize X\n",
    "X = X / 255.\n",
    "\n",
    "# Reshape image data to include greyscale parameter \n",
    "X = X.reshape(X.shape[0], 28, 28, 1)\n",
    "\n",
    "# One-hot encoding on y converting it to categorical\n",
    "y = np_utils.to_categorical(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/Test Split\n",
    "\n",
    "We want to create a validation set that the model will never see to approximate how it's going to do with Kaggle's `test.csv`. Use `sklearn`'s `train_test_split` to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28140, 28, 28, 1)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create your neural network\n",
    "\n",
    "Create a neural network using the `Dense` and `Dropout` layers from `keras`. Your activation function for the final output layer needs to be `softmax` to accomodate the ten different classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # The neural network includes...\n",
    "# model = Sequential()\n",
    "# model.add(Conv2D(15, kernel_size=(5,5), input_shape=(28, 28, 1), activation='relu'))  # input layer (features)\n",
    "# model.add(MaxPool2D((2,2)))                                                           # pooling to reduce spatial size\n",
    "# model.add(Conv2D(30, kernel_size=(4,4), activation='relu'))\n",
    "# model.add(MaxPool2D((2,2)))                                                           # pooling layer\n",
    "# model.add(Conv2D(45, kernel_size=(3,3), activation='relu'))\n",
    "# model.add(MaxPool2D((2,2)))                                                           # pooling layer\n",
    "# model.add(Flatten())\n",
    "# model.add(Dense(50, activation='relu'))\n",
    "# model.add(Dense(10, activation='softmax'))                                           # output layer (predictions)\n",
    "# # loss: 0.0458 - acc: 0.9854 - val_loss: 0.0680 - val_acc: 0.9800\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(20, kernel_size=(5,5), input_shape=(28, 28, 1), activation='relu'))  # input layer (features)\n",
    "model.add(MaxPool2D((2,2)))                                                           # pooling to reduce spatial size\n",
    "model.add(Conv2D(40, kernel_size=(4,4), activation='relu'))\n",
    "model.add(MaxPool2D((2,2)))                                                           # pooling layer\n",
    "model.add(Conv2D(80, kernel_size=(3,3), activation='relu'))\n",
    "model.add(MaxPool2D((2,2)))                                                           # pooling layer\n",
    "model.add(Flatten())\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))                                           # output layer (predictions)\n",
    "# loss: 0.0355 - acc: 0.9886 - val_loss: 0.0592 - val_acc: 0.9825\n",
    "\n",
    "# model = Sequential()\n",
    "# model.add(Conv2D(20, kernel_size=(5,5), input_shape=(28, 28, 1), activation='relu'))  # input layer (features)\n",
    "# model.add(MaxPool2D((2,2)))                                                           # pooling to reduce spatial size\n",
    "# model.add(Conv2D(40, kernel_size=(4,4), activation='relu'))\n",
    "# model.add(MaxPool2D((2,2)))                                                           # pooling layer\n",
    "# model.add(Conv2D(80, kernel_size=(3,3), activation='relu'))\n",
    "# model.add(MaxPool2D((2,2)))                                                           # pooling layer\n",
    "# model.add(Flatten())\n",
    "# model.add(Dense(50, activation='relu'))\n",
    "# model.add(Dense(25, activation='relu'))\n",
    "# model.add(Dense(10, activation='softmax'))                                           # output layer (predictions)\n",
    "# # loss: 0.0390 - acc: 0.9877 - val_loss: 0.0573 - val_acc: 0.9826"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile your model\n",
    "\n",
    "Since this is a multiclass classification problem, your loss function is `categorical_crossentropy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit the model\n",
    "\n",
    "Use your X_test, y_test from the `train_test_split` step for the `validation_data` parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 28140 samples, validate on 13860 samples\n",
      "Epoch 1/10\n",
      "28140/28140 [==============================] - 31s 1ms/step - loss: 0.3019 - acc: 0.9052 - val_loss: 0.1059 - val_acc: 0.9674\n",
      "Epoch 2/10\n",
      "28140/28140 [==============================] - 32s 1ms/step - loss: 0.0837 - acc: 0.9736 - val_loss: 0.0642 - val_acc: 0.9793\n",
      "Epoch 3/10\n",
      "28140/28140 [==============================] - 32s 1ms/step - loss: 0.0564 - acc: 0.9818 - val_loss: 0.0690 - val_acc: 0.9776\n",
      "Epoch 4/10\n",
      "28140/28140 [==============================] - 32s 1ms/step - loss: 0.0416 - acc: 0.9872 - val_loss: 0.0701 - val_acc: 0.9799\n",
      "Epoch 5/10\n",
      "28140/28140 [==============================] - 32s 1ms/step - loss: 0.0383 - acc: 0.9881 - val_loss: 0.0469 - val_acc: 0.9866\n",
      "Epoch 6/10\n",
      "28140/28140 [==============================] - 32s 1ms/step - loss: 0.0288 - acc: 0.9910 - val_loss: 0.0500 - val_acc: 0.9848\n",
      "Epoch 7/10\n",
      "28140/28140 [==============================] - 32s 1ms/step - loss: 0.0244 - acc: 0.9926 - val_loss: 0.0521 - val_acc: 0.9841\n",
      "Epoch 8/10\n",
      "28140/28140 [==============================] - 32s 1ms/step - loss: 0.0193 - acc: 0.9943 - val_loss: 0.0660 - val_acc: 0.9823\n",
      "Epoch 9/10\n",
      "28140/28140 [==============================] - 32s 1ms/step - loss: 0.0165 - acc: 0.9947 - val_loss: 0.0558 - val_acc: 0.9854\n",
      "Epoch 10/10\n",
      "28140/28140 [==============================] - 32s 1ms/step - loss: 0.0186 - acc: 0.9935 - val_loss: 0.0536 - val_acc: 0.9856\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x119c45860>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10)\n",
    "\n",
    "#loss: 0.0348 - acc: 0.9887 - val_loss: 0.0524 - val_acc: 0.9835\n",
    "#loss: 0.0186 - acc: 0.9935 - val_loss: 0.0536 - val_acc: 0.9856"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load in Kaggle's `test.csv`\n",
    "\n",
    "Be sure to do the **same** preprocessing you did for your training `X`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load testing dataframe\n",
    "testing = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Normalize columns in testing dataframe (similar to X columns in training dataframe)\n",
    "testing = testing / 255.\n",
    "\n",
    "# Reshape image data to include greyscale parameter \n",
    "testing = testing.values.reshape(testing.shape[0], 28, 28, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create your predictions\n",
    "\n",
    "Use `predict_classes` to get the actual numerical values (0-9)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28000/28000 [==============================] - 9s 304us/step\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict_classes(testing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare your submission\n",
    "\n",
    "1. Add your predictions to a column called `Label`\n",
    "2. You'll need to manually create the `ImageId` column, which is just a list of 1..[NUMBER OF TEST SAMPLES]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission = pd.DataFrame()\n",
    "submission['ImageId'] = range(1, testing.shape[0] + 1)\n",
    "submission['Label'] = predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create your submission csv\n",
    "\n",
    "Remember to set `index=False`!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Container.summary of <keras.models.Sequential object at 0x1c25cf3940>>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.to_csv('submission.csv', index=False)\n",
    "\n",
    "model.summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
